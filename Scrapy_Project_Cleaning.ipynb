{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "#from textblob import TextBlob\n",
    "import itertools\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atl = pd.read_csv('postings_atl.csv')\n",
    "bos = pd.read_csv('postings_bos.csv')\n",
    "chi = pd.read_csv('postings_chi.csv')\n",
    "den = pd.read_csv('postings_den.csv')\n",
    "la = pd.read_csv('postings_la.csv')\n",
    "nyc = pd.read_csv('postings_nyc.csv')\n",
    "sc = pd.read_csv('postings_sc.csv')\n",
    "sea = pd.read_csv('postings_sea.csv')\n",
    "sf = pd.read_csv('postings_sf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atl['metro'] = list(itertools.repeat('ATL', len(atl)))\n",
    "bos['metro'] = list(itertools.repeat('BOS', len(bos)))\n",
    "chi['metro'] = list(itertools.repeat('CHI', len(chi)))\n",
    "den['metro'] = list(itertools.repeat('DEN', len(den)))\n",
    "la['metro'] = list(itertools.repeat('LA', len(la)))\n",
    "nyc['metro'] = list(itertools.repeat('NYC', len(nyc)))\n",
    "sc['metro'] = list(itertools.repeat('SV', len(sc)))\n",
    "sea['metro'] = list(itertools.repeat('SEA', len(sea)))\n",
    "sf['metro'] = list(itertools.repeat('SF', len(sf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n",
      "['ceo_approve', 'company', 'job_description', 'location', 'rating', 'recommend_friend', 'salary_est', 'title', 'metro']\n"
     ]
    }
   ],
   "source": [
    "print(list(atl.columns.values))\n",
    "print(list(bos.columns.values))\n",
    "print(list(chi.columns.values))\n",
    "print(list(den.columns.values))\n",
    "print(list(la.columns.values))\n",
    "print(list(nyc.columns.values))\n",
    "print(list(sc.columns.values))\n",
    "print(list(sea.columns.values))\n",
    "print(list(sf.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7713, 9)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings = pd.concat([atl, bos, chi, den, la, nyc, sc, sea, sf], axis = 0)\n",
    "\n",
    "postings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salary_high = []\n",
    "for row in postings['salary_est']:\n",
    "    try: \n",
    "        salary_high.append(row[-4:-1].strip('$'))\n",
    "    except TypeError: \n",
    "        salary_high.append(np.nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ceo_approve</th>\n",
       "      <th>company</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommend_friend</th>\n",
       "      <th>salary_est</th>\n",
       "      <th>title</th>\n",
       "      <th>metro</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>salary_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>SunTrust Banks –</td>\n",
       "      <td>Job Description, PPNR Stress Analytics Finance...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Est. Salary $69k-$100k</td>\n",
       "      <td>PPNR Stress Analytics Finance Manager</td>\n",
       "      <td>ATL</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>Careerbuilder –</td>\n",
       "      <td>Job Description,Data Science Fall 2017 Interns...</td>\n",
       "      <td>Norcross, GA</td>\n",
       "      <td>3.7</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Fall 2017 Internship - Recommenda...</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.0</td>\n",
       "      <td>SPH Analytics –</td>\n",
       "      <td>Job Description, Data Analyst ,General Duties:...</td>\n",
       "      <td>Duluth, GA</td>\n",
       "      <td>2.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Est. Salary $58k-$77k</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ATL</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>T-Mobile –</td>\n",
       "      <td>Job Description, A creative development role o...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3.9</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developer, Software – Workforce Management Ana...</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.0</td>\n",
       "      <td>LiveHealthier –</td>\n",
       "      <td>Job Description, Position Purpose: Responsible...</td>\n",
       "      <td>Smyrna, GA</td>\n",
       "      <td>2.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Est. Salary $53k-$68k</td>\n",
       "      <td>Data Analyst IV</td>\n",
       "      <td>ATL</td>\n",
       "      <td>53.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ceo_approve             company  \\\n",
       "0         77.0   SunTrust Banks –    \n",
       "1         86.0    Careerbuilder –    \n",
       "2         98.0    SPH Analytics –    \n",
       "3         96.0         T-Mobile –    \n",
       "4         67.0    LiveHealthier –    \n",
       "\n",
       "                                     job_description      location  rating  \\\n",
       "0  Job Description, PPNR Stress Analytics Finance...   Atlanta, GA     3.1   \n",
       "1  Job Description,Data Science Fall 2017 Interns...  Norcross, GA     3.7   \n",
       "2  Job Description, Data Analyst ,General Duties:...    Duluth, GA     2.8   \n",
       "3  Job Description, A creative development role o...   Atlanta, GA     3.9   \n",
       "4  Job Description, Position Purpose: Responsible...    Smyrna, GA     2.8   \n",
       "\n",
       "   recommend_friend               salary_est  \\\n",
       "0              52.0   Est. Salary $69k-$100k   \n",
       "1              68.0                      NaN   \n",
       "2              49.0    Est. Salary $58k-$77k   \n",
       "3              82.0                      NaN   \n",
       "4              55.0    Est. Salary $53k-$68k   \n",
       "\n",
       "                                               title metro  salary_low  \\\n",
       "0              PPNR Stress Analytics Finance Manager   ATL        69.0   \n",
       "1  Data Science Fall 2017 Internship - Recommenda...   ATL         NaN   \n",
       "2                                       Data Analyst   ATL        58.0   \n",
       "3  Developer, Software – Workforce Management Ana...   ATL         NaN   \n",
       "4                                    Data Analyst IV   ATL        53.0   \n",
       "\n",
       "   salary_high  salary_range  salary_mid  \n",
       "0        100.0          31.0        84.5  \n",
       "1          NaN           NaN         NaN  \n",
       "2         77.0          19.0        67.5  \n",
       "3          NaN           NaN         NaN  \n",
       "4         68.0          15.0        60.5  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings['salary_low'] = postings['salary_est'].str.extract('(\\d+)').astype(float)  \n",
    "postings['salary_high'] = salary_high\n",
    "postings['salary_high'] = postings['salary_high'].astype(float)\n",
    "postings['salary_range'] = postings['salary_high'] - postings['salary_low']\n",
    "postings['salary_mid'] = postings['salary_low'] + (postings['salary_range']/2)\n",
    "\n",
    "postings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings['company'] = postings['company'].str.replace(' – ', '').str.strip()\n",
    "postings['company'] = postings['company'].str.replace('Amazon.com', 'Amazon')\n",
    "postings['company'] = postings['company'].str.replace('Amazon Web Services, Inc.', 'Amazon Web Services')\n",
    "postings['company'] = postings['company'].str.replace('KPMG US', 'KPMG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = []\n",
    "for row in postings['location']:\n",
    "    state.append(row[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city = []\n",
    "for row in postings['location']:\n",
    "    city.append(row[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings['city'] = city\n",
    "postings['state'] = state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings = postings.drop('location', 1)\n",
    "postings = postings.drop('salary_est', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ceo_approve</th>\n",
       "      <th>company</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommend_friend</th>\n",
       "      <th>title</th>\n",
       "      <th>metro</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>salary_mid</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Global Software Resources</td>\n",
       "      <td>Job Description,Job Description – Data Scienti...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SF</td>\n",
       "      <td>127.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Avenue Code</td>\n",
       "      <td>Job Description, Avenue Code is an eCommerce c...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SF</td>\n",
       "      <td>116.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Supercell</td>\n",
       "      <td>Job Description, Description ,Food for thought...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SF</td>\n",
       "      <td>97.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>88.0</td>\n",
       "      <td>The Climate Corp</td>\n",
       "      <td>Job Description, Description ,Position Overvie...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SF</td>\n",
       "      <td>138.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>DataRobot</td>\n",
       "      <td>Job Description,Job Summary, As a Customer Fac...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Partners - Customer Facing Data Scientist</td>\n",
       "      <td>SF</td>\n",
       "      <td>97.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ceo_approve                    company  \\\n",
       "7708         36.0  Global Software Resources   \n",
       "7709        100.0                Avenue Code   \n",
       "7710        100.0                  Supercell   \n",
       "7711         88.0           The Climate Corp   \n",
       "7712         -1.0                  DataRobot   \n",
       "\n",
       "                                        job_description  rating  \\\n",
       "7708  Job Description,Job Description – Data Scienti...     2.9   \n",
       "7709  Job Description, Avenue Code is an eCommerce c...     4.3   \n",
       "7710  Job Description, Description ,Food for thought...     4.4   \n",
       "7711  Job Description, Description ,Position Overvie...     3.9   \n",
       "7712  Job Description,Job Summary, As a Customer Fac...     4.0   \n",
       "\n",
       "      recommend_friend                                      title metro  \\\n",
       "7708              35.0                             Data Scientist    SF   \n",
       "7709              96.0                             Data Scientist    SF   \n",
       "7710              81.0                             Data Scientist    SF   \n",
       "7711              76.0                             Data Scientist    SF   \n",
       "7712              73.0  Partners - Customer Facing Data Scientist    SF   \n",
       "\n",
       "      salary_low  salary_high  salary_range  salary_mid           city state  \n",
       "7708       127.0        187.0          60.0       157.0  San Francisco    CA  \n",
       "7709       116.0        160.0          44.0       138.0  San Francisco    CA  \n",
       "7710        97.0        135.0          38.0       116.0  San Francisco    CA  \n",
       "7711       138.0        190.0          52.0       164.0  San Francisco    CA  \n",
       "7712        97.0        135.0          38.0       116.0  San Francisco    CA  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#postings = postings[np.isfinite(postings['ceo_approve'])]  # don't want to do this\n",
    "postings.index=(range(0, 7713))\n",
    "postings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#postings.to_csv('postings_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data-science indicators:\n",
    "\n",
    "postings['python'] = postings['job_description'].str.contains('python', case=False)==True\n",
    "postings['scikit'] = postings['job_description'].str.contains('scikit', case=False)==True\n",
    "postings['r'] = postings['job_description'].str.contains(' r, | r |\"r\"', case=False)==True\n",
    "postings['sql'] = postings['job_description'].str.contains('sql', case=False)==True\n",
    "postings['matlab'] = postings['job_description'].str.contains('matlab', case=False)==True\n",
    "postings['sas'] = postings['job_description'].str.contains(' sas', case=False)==True\n",
    "postings['phd'] = postings['job_description'].str.contains('phd|ph.d|doctorate', case=False)==True\n",
    "postings['masters'] = postings['job_description'].str.contains('msc|master', case=False)==True\n",
    "postings['statistic'] = postings['job_description'].str.contains('statistic', case=False)==True\n",
    "postings['visualization'] = postings['job_description'].str.contains('visualization', case=False)==True\n",
    "postings['tableau'] = postings['job_description'].str.contains('tableau', case=False)==True\n",
    "postings['ml'] = postings['job_description'].str.contains('machine learning', case=False)==True\n",
    "postings['nlp'] = postings['job_description'].str.contains('natural language processing', case=False)==True\n",
    "postings['hadoop'] = postings['job_description'].str.contains('hadoop', case=False)==True\n",
    "postings['spark'] = postings['job_description'].str.contains('spark', case=False)==True\n",
    "postings['java'] = postings['job_description'].str.contains('java', case=False)==True\n",
    "postings['mongo'] = postings['job_description'].str.contains('mongo', case=False)==True\n",
    "postings['hive'] = postings['job_description'].str.contains('hive', case=False)==True\n",
    "postings['c#'] = postings['job_description'].str.contains('c#', case=False)==True\n",
    "postings['linux'] = postings['job_description'].str.contains('linux', case=False)==True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clinical scientist/medical/health care indicators:\n",
    "\n",
    "postings['biolog'] = postings['job_description'].str.contains('biolog', case=False)==True\n",
    "postings['pharm'] = postings['job_description'].str.contains('pharm', case=False)==True\n",
    "postings['clinic'] = postings['job_description'].str.contains('clinic', case=False)==True\n",
    "postings['immun'] = postings['job_description'].str.contains('immun', case=False)==True\n",
    "postings['chemistry'] = postings['job_description'].str.contains('chemistry', case=False)==True\n",
    "postings['oncology'] = postings['job_description'].str.contains('oncology', case=False)==True\n",
    "postings['biochemistry'] = postings['job_description'].str.contains('biochemistry', case=False)==True\n",
    "postings['neuro'] = postings['job_description'].str.contains('neuro', case=False)==True\n",
    "postings['medical'] = postings['job_description'].str.contains('medical', case=False)==True\n",
    "postings['disease'] = postings['job_description'].str.contains('disease', case=False)==True\n",
    "postings['physician'] = postings['job_description'].str.contains('physician', case=False)==True\n",
    "postings['surgeon'] = postings['job_description'].str.contains('surgeon', case=False)==True\n",
    "postings['nurse'] = postings['job_description'].str.contains('nurse', case=False)==True\n",
    "postings['hospital'] = postings['job_description'].str.contains('hospital', case=False)==True\n",
    "postings['diseases'] = postings['job_description'].str.contains('hiv|hepatitis', case=False)==True\n",
    "postings['cancer'] = postings['job_description'].str.contains('cancer', case=False)==True\n",
    "postings['vaccine'] = postings['job_description'].str.contains('vaccine', case=False)==True\n",
    "postings['protein'] = postings['job_description'].str.contains('protein', case=False)==True\n",
    "postings['specimen'] = postings['job_description'].str.contains('specimen', case=False)==True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#postings.to_csv('postings_categorical.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = list(postings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biolog',\n",
       " 'pharm',\n",
       " 'clinic',\n",
       " 'immun',\n",
       " 'chemistry',\n",
       " 'oncology',\n",
       " 'biochemistry',\n",
       " 'neuro',\n",
       " 'medical',\n",
       " 'disease',\n",
       " 'physician',\n",
       " 'surgeon',\n",
       " 'nurse',\n",
       " 'hospital',\n",
       " 'diseases',\n",
       " 'cancer',\n",
       " 'vaccine',\n",
       " 'protein',\n",
       " 'specimen']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = col_list[-19:]\n",
    "\n",
    "col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed = postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed['biol_indicator'] = postings_trimmed[col_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed = postings_trimmed.loc[postings_trimmed.biol_indicator<5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = list(postings_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biolog',\n",
       " 'pharm',\n",
       " 'clinic',\n",
       " 'immun',\n",
       " 'chemistry',\n",
       " 'oncology',\n",
       " 'biochemistry',\n",
       " 'neuro',\n",
       " 'medical',\n",
       " 'disease',\n",
       " 'physician',\n",
       " 'surgeon',\n",
       " 'nurse',\n",
       " 'hospital',\n",
       " 'diseases',\n",
       " 'cancer',\n",
       " 'vaccine',\n",
       " 'protein',\n",
       " 'specimen',\n",
       " 'biol_indicator']"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = col_list[-20:]\n",
    "\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed = postings_trimmed.drop(col_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = list(postings_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'scikit',\n",
       " 'r',\n",
       " 'sql',\n",
       " 'matlab',\n",
       " 'sas',\n",
       " 'phd',\n",
       " 'masters',\n",
       " 'statistic',\n",
       " 'visualization',\n",
       " 'tableau',\n",
       " 'ml',\n",
       " 'nlp',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'mongo',\n",
       " 'hive',\n",
       " 'c#',\n",
       " 'linux']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = col_list[-20:]\n",
    "\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed['data_sci_indicator'] = postings_trimmed[col_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed = postings_trimmed.loc[postings_trimmed.data_sci_indicator>1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed = postings_trimmed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed.index=(range(0, 4941))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postings_trimmed.to_csv('postings_trimmed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
